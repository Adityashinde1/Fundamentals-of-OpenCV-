{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is Computer Vision ?**\n",
    "\n",
    "- Computer Vision is a field that care about how computers can gain a high-level understanding from digital images/videos. It is an attempt to automate tasks that the human visual system is able to perform. This is a process of **acquiring, processing, analyzing, and understanding digital images, and extracting high-dimensional data from the real world (to produce numerical/symbolic information.)**\n",
    "\n",
    "\n",
    "\n",
    "- Typical tasks involved Python Computer Vision are:\n",
    "    - Recognition\n",
    "    - Motion Analysis\n",
    "    - Scene Reconstruction\n",
    "    - Image Restoration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is  OpenCV ?**\n",
    "\n",
    "- **Gary Bradsky** started OpenCV at Intel in 1999. While it supports languages like C++, Python, and more, and OpenCV-Python is an API for OpenCV to unleash the power of Python and the OpenCV C++ API at once.\n",
    "\n",
    "- Python-OpenCV is just a wrapper around the original C/C++ code. It is normally used for combining best features of both the languages, **Performance of C/C++** & **Simplicity of Python**.\n",
    "\n",
    "- OpenCV (Open Source Computer Vision Library) is an open source computer vision and machine learning software library.This library uses **NumPy** and all its array structures convert to and from **NumPy arrays**. This also means we can integrate it easily with other libraries like **SciPy** and **Matplotlib (these make use of NumPy)**.\n",
    "\n",
    "- The library has more than 2500 optimized algorithms, which includes a comprehensive set of both classic and state-of-the-art computer vision and machine learning algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Installing OpenCV in Python**\n",
    "\n",
    "\n",
    "- Before you can install OpenCV, make sure you have **Python** and **NumPy** installed on your machine.\n",
    "- Use Script to install OpenCV  **`pip install opencv-python`**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load an Image** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 ### Load opencv \n",
    "\n",
    "image = cv2.imread('images/1.jpg') ### returns a NumPy array representing the image.\n",
    "cv2.imshow(\"test\", image) ### display the image in a window\n",
    "cv2.waitKey(0) ### pauses the execution of the script until we press a key on our keyboard\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If everything has worked correctly, you should see your image in  window."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Image Basics**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic building block of image is yes you guessed it right it's pixels. \n",
    "\n",
    "- What is a Pixel ?\n",
    "    - Normally, we think of a pixel as the **color** or the **intensity** of light that appears in a given place in our image.\n",
    "    \n",
    "    - If we think of an image as a grid, each square in the grid\n",
    "        contains a single pixel.\n",
    "    - Most pixels are represented in two ways: grayscale and\n",
    "        color. \n",
    "     - In a grayscale image, each pixel has a value between\n",
    "        0 and 255, where zero corresponds to “black” and 255 corresponds\n",
    "        to “white”. The values in between 0 and 255 are\n",
    "        varying shades of gray, where values closer to 0 are darker\n",
    "        and values closer to 255 are lighter.\n",
    "      - Color pixels are normally represented in the RGB color\n",
    "        space – one value for the Red component, one for Green,\n",
    "        and one for Blue.\n",
    "      - We then combine these values into an RGB tuple in the\n",
    "        form (red, green, blue). This tuple represents our color."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Coordinate System\n",
    "    - As I mentioned above, an image is represented as a grid of\n",
    "pixels. Imagine our grid as a piece of graph paper. Using\n",
    "this graph paper, the point (0, 0) corresponds to the upper\n",
    "left corner of the image. As we move down and to the right,\n",
    "both the x and y values increase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accessing and manipulating pixels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 28  35  30]\n",
      "  [ 27  34  29]\n",
      "  [ 25  32  27]\n",
      "  ...\n",
      "  [  7   7   7]\n",
      "  [  7   7   7]\n",
      "  [  7   7   7]]\n",
      "\n",
      " [[ 28  35  30]\n",
      "  [ 27  34  29]\n",
      "  [ 25  32  27]\n",
      "  ...\n",
      "  [  7   7   7]\n",
      "  [  7   7   7]\n",
      "  [  7   7   7]]\n",
      "\n",
      " [[ 26  36  30]\n",
      "  [ 25  35  29]\n",
      "  [ 23  33  27]\n",
      "  ...\n",
      "  [  7   7   7]\n",
      "  [  7   7   7]\n",
      "  [  7   7   7]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 99 106 101]\n",
      "  [ 98 108 102]\n",
      "  [100 107 102]\n",
      "  ...\n",
      "  [ 92 104  98]\n",
      "  [ 92 104  98]\n",
      "  [ 92 104  98]]\n",
      "\n",
      " [[100 106 101]\n",
      "  [ 99 106 101]\n",
      "  [100 106 101]\n",
      "  ...\n",
      "  [ 91 103  97]\n",
      "  [ 91 103  97]\n",
      "  [ 91 103  97]]\n",
      "\n",
      " [[100 106 101]\n",
      "  [100 106 101]\n",
      "  [100 106 101]\n",
      "  ...\n",
      "  [ 91 103  97]\n",
      "  [ 91 103  97]\n",
      "  [ 91 103  97]]]\n",
      "Pixel at (0, 0) - Red: 30, Green: 35, Blue: 28\n",
      "Pixel at (0, 0) - Red: 255, Green: 0, Blue: 0\n"
     ]
    }
   ],
   "source": [
    "image = cv2.imread('images/1.jpg')\n",
    "print(image)\n",
    "(b, g, r) = image[0, 0]\n",
    "print(\"Pixel at (0, 0) - Red: {}, Green: {}, Blue: {}\".format(r,g, b))\n",
    "\n",
    "image[0, 0] = (0, 0, 255)\n",
    "(b, g, r) = image[0, 0]\n",
    "print(\"Pixel at (0, 0) - Red: {}, Green: {}, Blue: {}\".format(r,g, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "corner = image[0:100, 0:100]\n",
    "cv2.imshow(\"Corner\", corner)\n",
    "\n",
    "image[0:100, 0:100] = (0, 255, 0)\n",
    "cv2.imshow(\"Updated\", image)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Drawing in OpenCV** \n",
    "\n",
    "Using NumPy array slices we were able to\n",
    "draw a green square on our image. But what if we wanted\n",
    "to draw a single line? Or a circle? NumPy does not provide\n",
    "that type of functionality – it’s only a numerical processing\n",
    "library after all!\n",
    "\n",
    "\n",
    "Luckily, OpenCV provides convenient, easy-to-use methods\n",
    "to draw shapes on an image.We’ll review\n",
    "the three most basic methods to draw shapes: \n",
    "`cv2.line`, `cv2.rectangle`, and `cv2.circle`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "canvas = np.zeros((300,300,3))\n",
    "\n",
    "red = (0,0,255)\n",
    "green = (0,255,0)\n",
    "blue = (255,0,0)\n",
    "\n",
    "cv2.line(canvas,(0,0),(300,300),green)\n",
    "cv2.imshow('Canvas',canvas)\n",
    "\n",
    "cv2.line(canvas,(300,0),(0,300),blue,3)\n",
    "cv2.imshow('Canvas',canvas)\n",
    "\n",
    "cv2.rectangle(canvas, (10, 10), (60, 60), green)\n",
    "cv2.imshow(\"Canvas\", canvas)\n",
    "\n",
    "cv2.rectangle(canvas, (50, 200), (200, 225), blue, 5)\n",
    "cv2.imshow(\"Canvas\", canvas)\n",
    "\n",
    "\n",
    "cv2.rectangle(canvas, (200, 50), (225, 125), red, -1)\n",
    "cv2.imshow(\"Canvas\", canvas)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "canvas = np.zeros((300, 300, 3))\n",
    "(centerX, centerY) = (canvas.shape[1] // 2, canvas.shape[0] // 2)\n",
    "white = (255, 255, 255)\n",
    "for r in range(0, 175, 25):\n",
    "    cv2.circle(canvas, (centerX, centerY), r, white)\n",
    "cv2.imshow(\"Canvas\", canvas)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 25):\n",
    "    radius = np.random.randint(5, 200)\n",
    "    color = np.random.randint(0,256, (3,)).tolist()\n",
    "    pt = np.random.randint(0, 300,(2,))\n",
    "    cv2.circle(canvas, tuple(pt), radius, color,-1)\n",
    "    \n",
    "    \n",
    "cv2.imshow(\"Canvas\", canvas)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Image Processing**\n",
    "\n",
    "Now that you have a solid foundation to build upon, we\n",
    "can start to exploring simple image processing techniques.\n",
    "First, we’ll start off with basic image transformations,\n",
    "such as **translation, rotation, resizing, flipping, and cropping**.\n",
    "\n",
    "\n",
    "- **Translation**\n",
    "\n",
    "    The first method we are going to explore is translation.\n",
    "    Translation is the shifting of an image along the x and y\n",
    "    axis. Using translation, we can shift an image up, down,\n",
    "    left, or right, along with any combination of the above!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image = cv2.imread('images/1.jpg')\n",
    "cv2.imshow('Image',image)\n",
    "\n",
    "M  = np.float32([[1,0,25],[0,1,50]]) \n",
    "shifted = cv2.warpAffine(image,M,(image.shape[1],image.shape[0]))\n",
    "cv2.imshow('shifted down and right',shifted)\n",
    "\n",
    "M  = np.float32([[1,0,-50],[0,1,-90]]) \n",
    "shifted = cv2.warpAffine(image,M,(image.shape[1],image.shape[0]))\n",
    "cv2.imshow('shifted up and left',shifted)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Rotation**\n",
    "\n",
    "Rotation is exactly what it sounds like: rotating an image\n",
    "by some angle q. In this section, we’ll explore how to rotate\n",
    "an image. We’ll use q to represent by how many degrees\n",
    "we are rotating the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('images/1.jpg')\n",
    "cv2.imshow('Original',image)\n",
    "\n",
    "(h,w) = image.shape[:2]\n",
    "center = (w//2,h//2)\n",
    "\n",
    "M = cv2.getRotationMatrix2D(center,-45,1.0)\n",
    "rotated = cv2.warpAffine(image,M,(w,h))\n",
    "\n",
    "cv2.imshow('Rotated by 45 degrees',rotated)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Resizing**\n",
    "\n",
    "So far we’ve covered two image transformations: translation\n",
    "and rotation. Now, we are going to explore how to\n",
    "resize an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5791505791505791\n"
     ]
    }
   ],
   "source": [
    "image = cv2.imread('images/1.jpg')\n",
    "cv2.imshow('Original',image)\n",
    "\n",
    "r = 150.0/image.shape[1]\n",
    "print(r)\n",
    "dim = (150,int(image.shape[0]*r))\n",
    "\n",
    "resized = cv2.resize(image,dim,interpolation = cv2.INTER_AREA)\n",
    "cv2.imshow('Resized Image',resized)\n",
    "\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Flipping**\n",
    "\n",
    "Next up on our image transformations to explore is flipping\n",
    "an image. We can flip an image around either the x or\n",
    "y axis, or even both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('images/1.jpg')\n",
    "cv2.imshow('Original',image)\n",
    "\n",
    "\n",
    "flipped = cv2.flip(image, 1)\n",
    "cv2.imshow(\"Flipped Horizontally\", flipped)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Cropping**\n",
    "\n",
    "When we crop an image, we want to remove the outer parts\n",
    "of the image that we are not interested in. We can accomplish\n",
    "image cropping by using NumPy array slicing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('images/1.jpg')\n",
    "cv2.imshow('Original',image)\n",
    "\n",
    "cropped = image[0:100,0:100]\n",
    "cv2.imshow(\"Cropped\", cropped)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Smoothing and Blurring**\n",
    "\n",
    "- I’m pretty sure we all know what blurring is. It’s what\n",
    "    happens when your camera takes a picture out of focus.\n",
    "    Sharper regions in the image lose their detail, normally as\n",
    "    a disc/circular shape.\n",
    "\n",
    "- Practically, this means that each pixel in the image is\n",
    "    mixed in with its surrounding pixel intensities. This “mixture”\n",
    "    of pixels in a neighborhood becomes our blurred pixel.\n",
    "    \n",
    "    \n",
    "- While this effect is usually unwanted in our photographs,\n",
    "it’s actually quite helpful when performing image processing\n",
    "tasks.\n",
    "In fact, many image processing and computer vision functions,\n",
    "such as thresholding and edge detection, perform better\n",
    "if the image is first smoothed or blurred."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Averaging**\n",
    "\n",
    "The first blurring method we are going to explore is averaging.\n",
    "       \n",
    "As the name suggests, we are going to define a k x k sliding\n",
    "window on top of our image, where k is always an odd\n",
    "number. This window is going to slide from left-to-right\n",
    "and from top-to-bottom. The pixel at the center of this matrix\n",
    "(we have to use an odd number, otherwise there would\n",
    "not be a true “center”) is then set to be the average of all\n",
    "other pixels surrounding it.\n",
    "We call this sliding window a “convolution kernel” or\n",
    "just a “kernel” "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "image = cv2.imread('images/1.jpg')\n",
    "blurred = np.hstack([cv2.blur(image, (3, 3))])\n",
    "cv2.imshow('Blurred',blurred)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Gaussian**\n",
    "\n",
    "\n",
    "- Next up, we are going to review Gaussian blurring. Gaussian\n",
    "blurring is similar to average blurring, but instead of\n",
    "using a simple mean, we are now using a weighted mean,\n",
    "where neighborhood pixels that are closer to the central\n",
    "pixel contribute more “weight” to the average.\n",
    "- The end result is that our image is less blurred, but more\n",
    "naturally blurred, than using the average method discussed\n",
    "in the previous section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "image = cv2.imread('images/1.jpg')\n",
    "blurred = np.hstack([cv2.GaussianBlur(image, (11,11),0)])\n",
    "cv2.imshow('Blurred',blurred)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Thresholding**\n",
    "\n",
    "\n",
    "Thresholding is the binarization of an image. In general,\n",
    "we seek to convert a grayscale image to a binary image,\n",
    "where the pixels are either 0 or 255.\n",
    "A simple thresholding example would be selecting a pixel\n",
    "value p, and then setting all pixel intensities less than p to\n",
    "zero, and all pixel values greater than p to 255. In this way,\n",
    "we are able to create a binary representation of the image.\n",
    "Normally, we use thresholding to focus on objects or areas\n",
    "of particular interest in an image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Simple Thresholding**\n",
    "\n",
    "Applying simple thresholding methods requires human intervention.\n",
    "We must specify a threshold value T. All pixel\n",
    "intensities below T are set to 0. And all pixel intensities\n",
    "greater than T are set to 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('images/2.jpg')\n",
    "cv2.imshow('Original',image)\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "blurred = cv2.GaussianBlur(image, (5, 5), 0)\n",
    "\n",
    "\n",
    "(T, thresh) = cv2.threshold(blurred, 155, 255, cv2.THRESH_BINARY)\n",
    "(T, threshInv) = cv2.threshold(blurred, 155, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "cv2.imshow('Thresholding',threshInv)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Adaptive Thresholding**\n",
    "\n",
    "\n",
    "One of the downsides of using simple thresholding methods\n",
    "is that we need to manually supply our threshold value\n",
    "T. Not only does finding a good value of T require a lot of\n",
    "manual experiments and parameter tunings, it’s not very helpful if the image exhibits a lot of range in pixel intensities.\n",
    "\n",
    "Simply put, having just one value of T might not suffice.\n",
    "In order to overcome this problem, we can use adaptive\n",
    "thresholding, which considers small neighbors of pixels\n",
    "and then finds an optimal threshold value T for each neighbor.\n",
    "This method allows us to handle cases where there\n",
    "may be dramatic ranges of pixel intensities and the optimal\n",
    "value of T may change for different parts of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('2.jpg')\n",
    "\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "blurred = cv2.GaussianBlur(image, (5, 5), 0)\n",
    "thresh = cv2.adaptiveThreshold(blurred,255,cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY_INV,11,4)\n",
    "\n",
    "thresh = cv2.adaptiveThreshold(blurred, 255,\n",
    "cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 15, 3)\n",
    "\n",
    "cv2.imshow(\"Gaussian Thresh\",thresh)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gradients and Edge Detection**\n",
    "\n",
    "This chapter is primarily concerned with gradients and\n",
    "edge detection. Formally, edge detection embodies mathematical\n",
    "methods to find points in an image where the\n",
    "brightness of pixel intensities changes distinctly.\n",
    "\n",
    "The first thing we are going to do is find the “gradient” of\n",
    "the grayscale image, allowing us to find edge-like regions\n",
    "in the x and y direction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('images/2.jpg')\n",
    "image = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow('Original',image)\n",
    "\n",
    "lap = cv2.Laplacian(image,cv2.CV_64F)\n",
    "\n",
    "lap = np.uint8(np.absolute(lap))\n",
    "cv2.imshow('Laplacian',lap)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Canny Edge Detection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('images/2.jpg')\n",
    "\n",
    "image = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "image = cv2.GaussianBlur(image, (5, 5), 0)\n",
    "cv2.imshow('Blurred',image)\n",
    "\n",
    "canny = cv2.Canny(image, 30, 150)\n",
    "cv2.imshow('Canny',canny)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Contours**\n",
    "\n",
    "Previously, we explored how to detect edges in an image\n",
    "of coins.\n",
    "Now we are going to use these edges to help us find the\n",
    "actual coins in the image and count them.\n",
    "OpenCV provides methods to find “curves” in an image,\n",
    "called contours. A contour is a curve of points, with no\n",
    "gaps in the curve. Contours are extremely useful for such\n",
    "things as shape approximation and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I Count 6 coins in this image\n"
     ]
    }
   ],
   "source": [
    "image = cv2.imread('images/2.jpg')\n",
    "\n",
    "gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "blurred = cv2.GaussianBlur(gray,(5,5),0)\n",
    "\n",
    "edged = cv2.Canny(blurred,30,150)\n",
    "cv2.imshow('Edge Detection',edged)\n",
    "\n",
    "\n",
    "(cnts, _) = cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL,\n",
    "cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "print('I Count {} coins in this image'.format(len(cnts)))\n",
    "coins = image.copy()\n",
    "\n",
    "cv2.drawContours(coins,cnts,-1,(0,255,0),2)\n",
    "cv2.putText(coins, '{} coins'.format(len(cnts)), (50, 50), cv2.FONT_HERSHEY_SIMPLEX,1,(0, 0, 255) , 5, cv2.LINE_AA) \n",
    "cv2.imshow('Coins',coins)\n",
    "\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion**\n",
    "\n",
    "- We’ve explored many image processing and computer vision techniques, including basic image processing,such as translation, rotating, and resizing.\n",
    "\n",
    "- Then moved on to blurring our images, using different methods,\n",
    "such as averaging, Gaussian, and median filtering.\n",
    "\n",
    "- We thresholded our images to find objects of interest,\n",
    "then applied edge detection.\n",
    "\n",
    "- Finally we learned how to use contours to count the number\n",
    "of coins in the image.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
